# -*- coding: utf-8 -*-
"""LinearData_sine_f.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wuJFNVOb8vFiPGYw8kYurr-ks_4L8Ptj

# Function Approximation with a Linear Model
$y=f(x)=\sin x$ <br />
Approximate this function with a linear function of the form <br />
$y = w_0 + w_1 x + w_2 x^2$ <br />
in the range $x\in(0,2\pi)$
"""

import numpy as np

"""### Generate data"""

def fx(x):
    '''
    Input:
        x: float (scalar) or np array
    Output:
        y: float (scalar) or np array; y=f(x)=sin(x)
        
    HINT: Use web search on how to take sine in numpy
    '''
    # YOUR CODE HERE
    y=np.sin(x)
    return y

'''Testing'''
def test_fx():
    assert fx(0)==0
    assert np.isclose(fx(np.pi/2), 1, atol=0.001)
    assert np.isclose(fx(np.pi/4), 0.707, atol=0.001)
    print('Test passed', '\U0001F44D')
test_fx()

def generateX_fx(N):
    '''
    Generate N random points in the range (0,2pi)
    Input:
        N: int
    Outputs:
        x: np vector of shape (N,)
        y: np vector of shape (N,); y=f(x)
    '''
    # YOUR CODE HERE
    x=np.random.random(N) * 2*3.14159
    y=np.sin(x)
    return x, y

generateX_fx(20)

'''Testing'''
def test_generateX_fx():
    x, yd = generateX_fx(20)
    assert x.shape[0]==20
    assert yd.shape[0]==20
    print('Test passed', '\U0001F44D')
test_generateX_fx()

"""### Plotting"""

def plotdata():
    x, yd = generateX_fx(20)
    import matplotlib.pyplot as plt
    i = x.argsort()
    plt.plot(x[i],yd[i])
    plt.ylabel('f(x)')
    plt.xlabel('x')
plotdata()

"""## Training
We will now define a linear model to estimate the above function, and train it with all the data

### Define model
$y = \sum_{d=0}^D w_d x^d$, here, $D$ is the degree of the model, say D=2 <br />

In matrix representation: y = Aw <br/>
"""

def createA(x, D):
    '''
    Create the matrix A with degree D
    Input:
        x: np vector of shape (N,)
        D: degree of the model
    Output:
        A: np matrix of shape (N,D+1)
    '''
    # YOUR CODE HERE
    A=[]
    for i in x:
      l=[]
      for j in range(D+1):
        l.append(i**j)
      A.append(l)
    return np.asarray(A)

x=[1,2,3]
D=2
createA(x,D)

'''Testing'''
def test_createA():
    x = np.array([1,2,3])
    A = createA(x, 2)
    assert A.shape==(3,3)
    assert np.all(A[0,:]==1)
    assert np.all(A==np.array([[1.0, 1.0, 1.0], [1.0, 2.0, 4.0], [1.0, 3.0, 9.0]]))
    print('Test passed', '\U0001F44D')
test_createA()



"""### Estimate Weights
Estimate w from yd and A. Use the least square solution you learnt in the video
"""

def train_w(A, yd):
    '''
    Inputs:
        A: np matrix of shape (N,D+1)
        yd: np vector of shape (N,)
    Output:
        w: np vector of shape (D+1,)
    '''
    # YOUR CODE HERE
    w=(np.linalg.inv(A.T.dot(A))).dot(A.T.dot(yd)) 
    print(w)
    
    
    return w

'''Testing'''
def test_train_w():
    A = np.array([[1.0, 1.0, 1.0], [1.0, 2.0, 4.0], [1.0, 3.0, 9.0]])
    yd = np.array([1,2,3])
    assert np.all(np.isclose(train_w(A, yd), np.array([0,1,0]), atol=.001))
    yd = yd*yd
    assert np.all(np.isclose(train_w(A, yd), np.array([0,0,1]), atol=.001))
    print('Test passed', '\U0001F44D')
test_train_w()

"""### Estimate y from the model, given x"""

def predict_y(w, x):
    '''
    Inputs:
        w: np vector of shape (D+1,)
        x: np vector of shape (N,)
    Outputs:
        y: np vector of shape (N,); y=Aw
    '''
    # YOUR CODE HERE
    A=[]
    D=w.shape[0]
    for i in x:
      l=[]
      for j in range(D):
        l.append(i**j)
      A.append(l)
    A= np.asarray(A)
    y=A.dot(w)
    
    return y

def test_predict_y():
    w = np.array([1,2,3])
    x = np.array([0.2,0.5,0.6])
    y = predict_y(w, x)
    assert np.all(np.isclose(y, np.array([1.52, 2.75, 3.28]), atol=0.001))
    print('Test passed', '\U0001F44D')
test_predict_y()

"""### Estimate Error
Find E as the mean squared error
"""

def compute_mse(y, yd):
    '''
    Inputs:
        y: np vector of shape (N,); y=Aw
        yd: np vector of shape (N,); yd=f(x), ie., desired or true value
    Output:
        mse: mean squared error
    '''
    # YOUR CODE HERE
    sum = 0
    for i in range(0,len(y)):
      y1=y[i]-yd[i]
      y1=y1*y1
      sum=sum+y1
    mse= sum/len(y)
    return mse

yd = np.array([1,0,1,0])
y = np.array([.8,.2,.8,.2])
compute_mse(y, yd)

'''Testing'''
def test_compute_mse():
    yd = np.array([1,0,1,0])
    y = np.array([.8,.2,.8,.2])
    assert np.isclose(compute_mse(y, yd), 0.04, atol=0.003)
    print('Test passed', '\U0001F44D')
test_compute_mse()

"""### Plotting"""

def plotModel(x, y, yd):
    import matplotlib.pyplot as plt
    i = x.argsort()
    plt.figure()
    plt.plot(x[i],y[i],'g-o')
    plt.plot(x[i],yd[i],'r-o')
    plt.ylabel('f(x)')
    plt.xlabel('x')
    plt.legend(['estimated', 'true'])

print(x)
print(y)
print(yd)

"""# EXPERIMENTS
## Could you train it?
Using the above functions:
- Generate 20 training points
- Train your linear model using x and yd
- Predict y (using the linear model you found above) for the training data x
- Compare y with yd to find the mean-squared error
"""

def trainModel(N, D):
    '''
    Inputs:
        N: number of samples
        D: degree of the model
    Outputs:
        x: np array of size (N,)
        y: np array of size (N,)
        yd: np array of size (N,)
        w: np array of size (D+1,)
        mse: scalar float
    '''
    # YOUR CODE HERE
    x=np.random.random(N) * 2*3.14159
    yd=np.sin(x)
    #return x, y
    A=[]
    for i in x:
      l=[]
      for j in range(D+1):
        l.append(i**j)
      A.append(l)
    A= np.asarray(A)
    w=(np.linalg.inv(A.T.dot(A))).dot(A.T.dot(yd)) 
    #return w
   
    y=A.dot(w)
    
    sum = 0
    for i in range(0,len(y)):
      y1=y[i]-yd[i]
      y1=y1*y1
      sum=sum+y1
    mse= sum/len(y)
    #return mse
    
    #return y
    return x, yd, y, w, mse

'''testing'''
def test_trainModel():
    N = 20
    D = 2
    x, y, yd, w, mse = trainModel(N,D)
    assert x.shape[0]==20
    assert w.shape[0]==D+1
    print(w)
    print('MSE on train data = ', mse)
#     plotModel(x,y,yd)
    print('Test passed', '\U0001F44D')
test_trainModel()

"""## Could you test it on new (test) points?
Using the above functions:
- Generate 30 test points
- Estimate y using the linear model w you found above. Do NOT train again
- Compare y with yd to find the mean-squared error <br />
"""

def testModel(Ntest, w):
    '''
    Inputs:
        Ntest: number of test samples to be generated
        w: np array of size (D+1,)
    Outputs:
        x: np array of size (N,)
        y: np array of size (N,)
        yd: np array of size (N,)
        mse: scalar float
    '''
    # YOUR CODE HERE
    x=np.random.random(Ntest) * 2*3.14159
    yd=np.sin(x)
    A=[]
    D=w.shape[0]
    for i in x:
      l=[]
      for j in range(D):
        l.append(i**j)
      A.append(l)
    A= np.asarray(A)
    y=A.dot(w)
    sum = 0
    for i in range(0,len(y)):
      y1=y[i]-yd[i]
      y1=y1*y1
      sum=sum+y1
    mse= sum/len(y)
    return x, y, yd, mse

'''Testing'''
def test_testModel():
    N = 30
    D = 10
    x, y, yd, w, mse = trainModel(N,D)
    assert x.shape[0]==N
    assert w.shape[0]==D+1
    print(w)
    print('MSE on train data = ', mse)
    plotModel(x,y,yd)
    Ntest = 50
    x, y, yd, mse = testModel(Ntest,w)
    print('MSE on test data = ', mse)
    plotModel(x,y,yd)
    print('Test passed', '\U0001F44D')
test_testModel()

"""# ADVANCED

## Does the performance improve with increasing the number of training points?
- Repeat the training with different no. of samples. Take N=3, 5, 10, 30; and D=5
- Plot training error vs N
- Plot test error vs N
"""

D = 5
MSE_train = []
MSE_test = []
N_all = [3,5,10,30]
for N in N_all:
  title = "N=%d; D=%d"%(N,D)
  print(title)
  x, y, yd, w, mse = trainModel(N,D)
  MSE_train.append(mse)
  print('MSE on train data = ', mse)
  plotModel(x,y,yd)
  Ntest = 50
  x, y, yd, mse = testModel(Ntest,w)
  MSE_test.append(mse)
  print('MSE on test data = ', mse)
  plotModel(x,y,yd)
plt.figure()
plt.plot(N_all, MSE_train,'go-')
plt.plot(N_all, MSE_test, 'ro-')
plt.legend(['train','test'])
plt.xlabel('N')
plt.ylabel('MSE')

"""## Does the performance improve with increasing the degree D of the model?
- Repeat the training with different degree models. Take D=0, 1, 2, 4, 7, 12, and N=10
- Plot training error vs D
- Plot test error vs D
- Plot y vs x for each D
"""

N=10
MSE_train = []
MSE_test = []
D_all = [0,1,2,4,7,12]
for D in D_all:
  title = "N=%d; D=%d"%(N,D)
  print(title)
  x, y, yd, w, mse = trainModel(N,D)
  MSE_train.append(mse)
  print('MSE on train data = ', mse)
  plotModel(x,y,yd)
  Ntest = 50
  x, y, yd, mse = testModel(Ntest,w)
  MSE_test.append(mse)
  print('MSE on test data = ', mse)
  plotModel(x,y,yd)
plt.figure()
MSE_train = np.array(MSE_train)
plt.plot(D_all, np.log(MSE_train+1),'go-')
MSE_test = np.array(MSE_test)
plt.plot(D_all, np.log(MSE_test+1), 'ro-')
plt.legend(['train','test'])
plt.xlabel('D')
plt.ylabel('MSE')

