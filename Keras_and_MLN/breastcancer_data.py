# -*- coding: utf-8 -*-
"""BreastCancer_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pXuZqy8Z8cz78p_DdKjKPvfVm53tJKg4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests

### Download data from google drive. You need not mess with this code.

import requests

def download_file_from_google_drive(id, destination):
    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()

    response = session.get(URL, params = { 'id' : id }, stream = True)
    token = get_confirm_token(response)

    if token:
        params = { 'id' : id, 'confirm' : token }
        response = session.get(URL, params = params, stream = True)

    save_response_content(response, destination)    

def get_confirm_token(response):
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            return value

    return None

def save_response_content(response, destination):
    CHUNK_SIZE = 32768

    with open(destination, "wb") as f:
        for chunk in response.iter_content(CHUNK_SIZE):
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)
                
if __name__ == "__main__":
    file_id = '1ih8PomVE7L3z_xReHAEsq3hk-0O1Uo12'
    destination = 'data.csv'
    download_file_from_google_drive(file_id, destination)

# Importing and cleaning data using pandas library
data = pd.read_csv('data.csv')
del data['Unnamed: 32']

## Observe the data
data

## We have left first two columns and taken other columns as input features
X = data.iloc[:, 2:].values

# 2nd column is output labels
y = data.iloc[:, 1].values

X

y

## Convert the output labels to numbers : M->0; B-> 1
## Store the output in Y_v
Y_v = []
for i in y:
  if i=='M':
    Y_v.append(0)
  else:
    Y_v.append(1)
Y_v=np.array(Y_v)

Y_v

"""Test for Y_v"""
print('Test passed', '\U0001F44D')

### One-hot encode Y_v
def oneHot(y, Ny):
    '''
    Input:
        y: an int in {0, 1}
        Ny: Number of classes, e.g., 2 here.
    Output:
        Y: a vector of Ny (=2) tuples
    '''
    # YOUR CODE HERE
    import keras
    Y=keras.utils.to_categorical(y, Ny)
    return Y

"""Test for one-hot"""
assert np.all(oneHot(0,3)==np.array([1,0,0]))
print('Test passed', '\U0001F44D')

Y_v=oneHot(Y_v,2)

### Split data into train and test. Keep 10% of samples for testing
## Divide the data into these variables - X_train, X_test, y_train, y_test

# YOUR CODE HERE
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X,Y_v, test_size = 0.1, random_state = 0)

"""test for splitting"""
assert(X_train.shape[0] == 512)
print('Test passed', '\U0001F44D')



## Normalize the Data
def findMeanStddev(X):
    '''
    Input: 
        X: a matrix of size (no. of samples, dimension of each sample)
    Output:
        mean: mean of samples in X (same size as X)
        stddev: element-wise std dev of sample in X (same size as X)
    '''
    # YOUR CODE HERE
    mean=np.sum(X,axis=0)/X.shape[0]
    stddev=np.sqrt(np.sum((X-mean)*(X-mean),axis=0)/X.shape[0])
    return mean, stddev

def normalizeX(X, mean, stddev):
    '''
    Input:
        X: a matrix of size (no. of samples, dimension of each sample)
        mean: mean of samples in X (same size as X)
        stddev: element-wise std dev of sample in X (same size as X) 
    Output:
        Xn: X modified to have 0 mean and 1 std dev
    '''
    # YOUR CODE HERE
    Xn=(X-mean)/(stddev+1e-8)
    return Xn
     
    
mean_train, stddev_train = findMeanStddev(X_train)  
X_train = normalizeX(X_train, mean_train, stddev_train)
X_test = normalizeX(X_test, mean_train, stddev_train)

"""test for normalizeX

#### Create model. 
- Choose the number of hidden layers, neurons, activations, loss function, learning rate and optimizers on your own.
- Report accuracy metric
- Use no more than 100 epochs
"""

import keras
from keras.layers import Input, Dense
from keras.models import Model
from keras import optimizers
from keras import metrics
def create_model():
    """
    Inputs:
        None
    Outputs:
        model: keras model afteer compiling
    """
    # YOUR CODE HERE
    x= Input(X_train.shape[1:] ,)
    a=Dense(20,activation='relu')(x)
    y=Dense(2,activation='softmax')(a)
    model=Model(inputs=x, outputs=y)
    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[metrics.categorical_accuracy])
    return model

model = create_model()

history = model.fit(X_train, y_train, epochs=50, batch_size = 2, validation_split = 0.1)

"""Evalutaion
- 2 points if accuracy > 0.80
- +1 point if accuracy > 0.90
- +1 point if accuracy > 0.95

Test for model
"""

y=model.predict(X_test)

def oneHot_tolabel(y):
    """
    Inputs:
        y: numpy array of shape (samples, Ny)
    Outputs:
        y_b: numpy array of shape (samples,) where one hot encoding is converted back to class labels
    """
    # YOUR CODE HERE
    y_b = np.argmax(y,axis=1)
    return y_b

def create_confusion_matrix(true_labels, predicted_labels):
    """
    Inputs:
        true_labels: numpy array of shape (samples, ) with true_labels
        test_labels: numpy array of shape(samples, ) with test_labels
    Outputs:
        cm: numpy array of shape (Ny, Ny), confusion matrix. Ny -> number of unique classes in y
    """
    # YOUR CODE HERE
    from sklearn.metrics import classification_report, confusion_matrix  
    cm = confusion_matrix(true_labels,predicted_labels)    
    return cm

cm = create_confusion_matrix(oneHot_tolabel(y_test), oneHot_tolabel(y))

cm

def accuracy(X_test, y_test, model):
    """
    Inputs:
        x_test: test samples
        y_test : test labels
        model: keras model
    Ouputs:
        acc: float, accuracy of test data on model
    """
    # YOUR CODE HERE
    from sklearn.metrics import confusion_matrix
    acc = model.evaluate(X_test, y_test,verbose=0)
    return acc

acc = accuracy(X_test, y_test, model)
print('Test accuracy is, ', acc[-1]*100, '%')

