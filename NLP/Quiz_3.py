# -*- coding: utf-8 -*-
"""Copy of Shivangi Gupta - NLP_Quiz_3_f.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XNCcB5DQOZte9f659S_hegO_75Y349Rr

## 1)  Loading and cleaning raw dataset 
In [SLNI_dataset](https://raw.githubusercontent.com/Jivnesh/ISCLS-19/master/data/sample_snli.jsonl), each line containes one data-sample.
"""

import json
import numpy as np
from tqdm import tqdm
!wget https://raw.githubusercontent.com/Jivnesh/ISCLS-19/master/data/sample_snli.jsonl
!ls
file_name='sample_snli.jsonl'
json_data = []
with open(file_name) as data_file:
  for l in data_file:
    json_data.append(json.loads(l))
print('Dataset loaded.')

json_data[0]

print(json_data[0]['gold_label'])
print(json_data[0]['sentence1'])
print(json_data[0]['sentence2'])

for i in range(5):
    print(json_data[i]['gold_label'])

"""### Preprocessing started
 First datapoint is printed above for your  better understanding of how data looks. <br>
 Each data-sample has different attributes like annotator_labels, captionID, gold_label, pairID, sentence1, sentence2 etc. So we are interested in three attributes, namely, sentence1, sentence2 and gold_label.
The 'gold_label' field contains the label ('entailment', 'neutral' or 'contradiction') for each data point. There are some data points that don't have the gold_label (their value for the gold label field is '-'). We will only use those examples which have a gold label. Your job is to extract these three attributes (sentence1, sentence2 and gold_label) and preprocess it. <br>
 You need to complete obtain_data function. It has two parts.<br>


1.   Filter out data points without a gold label and extract each sentence pair into a triple and concatenate them altogether into a list. For example,   triple = (s1, s2, label).
2.  Build the set of tokens from collection of  all sentence pairs (sentence1 and sentence2 of each sample). For example, your set of tokens will look like { '2',
 '9',
 'A',
 'An',
 'Angeles',
 'Asian-themed',
 'At',
 'Chinese',
 'Doctors'}
"""

def obtain_data(json_data):
    """
    Input:
        json_data: list (with each row of this list being a dictionary)
    
    Action:
    
        1. Ignore data points without a gold label
        2. Extract each sentence pair into a tuple of size 3 and concatenate them altogether into a list.
        
        i.e., for each item in json_data, store sentence1, sentence2 and gold_label values into 'example' list if gold_label != '-'
        
        example = (sentence1, sentence2, gold_label)
        append the 'example' tuple into list 'data' 
        data.append(example)
        
    Output:
        data: list of tuples of size 3
    """ 
    # YOUR CODE HERE
    data=[]
    for i in json_data:
      if i['gold_label'] != '-':
        temp=(i['sentence1'],i['sentence2'],i['gold_label'])
        data.append(temp)
        
    return data
    
data = obtain_data(json_data)

data

'''test for obtain_data'''

def tokens(json_data):
    """
    Input:
        json_data: list (with each row of this list being a dictionary)
       
    Output: 
        voc_set: list, list of unique words in json_data (only consider those elements of json_data for which gold_label is not '-')
    """
    # YOUR CODE HERE
    voc_set=[]
    temp1=[]
    temp2=[]
    temp3=[]
    for i in json_data:
      if i['gold_label'] != '-':
        temp1.append(i['sentence1'])
        temp2.append(i['sentence2'])
    for text in temp1:
      temp3.append(text.split(" "))
    for text in temp2:
      temp3.append(text.split(" "))
     
    for i in temp3:
      for j in i:
        if j not in voc_set:
          voc_set.append(j)
    
    return(voc_set)
      

voc_set = tokens(json_data)

print(voc_set)
print(len(voc_set))

'''test for tokens'''

"""## Build your vocabulary
Implement following three functions:

 
1.  **make_wtoi_dict**, word-to-integer is a python dictionary which can be used to map a word into a unique id. For example, stoi('hello') # This will give you an integer id  whose word map  is '*hello*'.
2. **itow**, integer-to-word is a python dictionary which can be used to map a given id into the corresponding word. For example, itos(100) # This will give you the word whose id is 100.
3.   Numericalize your data in the **process_data** function, namely convert the sentences into a list of ids and the labels into label_ids. (Use the stoi function and  label_id in the cell below for mapping.). Your output for ['Two women are embracing while holding to go packages.',
 'The sisters are hugging goodbye while holding to go packages after just eating lunch.',
 'neutral'] should look like ([44, 39, 13, 192, 231, 102, 141, 246, 168],
  [43, 133, 13, 151, 135, 231, 102, 141, 246, 71, 185, 170, 159, 178],
  1)
"""

def make_wtoi_dict(voc_set):
    """
    Input: 
        voc_set: list, list of unique words
        
    Output: 
         wtoi_dict: dictionary, keys are words in voc_set, values are unique integer ids for each word between 0 and len(voc_set)-1         
    """
    # YOUR CODE HERE
    
    wtoi_dict={}
    l=list(voc_set)
    i=0
    for j in l:
      wtoi_dict[j]=i
      i=i+1
    return wtoi_dict
  
wtoi_dict = make_wtoi_dict(voc_set)

print(wtoi_dict)

def make_itow_dict(wtoi_dict):
    """
      Maps unique integer ids to words
      Input: 
          wtoi_dict: dictionary, contains word to integer mappings

      Output:
          itow_dict : dictionary, for each key, value in wtoi_dict - itow_dict should have a corresponding value, key pair

    """
    # YOUR CODE HERE
    itow_dict={}
    for k, v in wtoi_dict.items():
      itow_dict[v] = k
    return itow_dict
  
itow_dict = make_itow_dict(wtoi_dict)

print(itow_dict)

def wtoi(word, wtoi_dict):
  """
  Inputs:
    word: string, word for which id is required
    wtoi_dict: dictionary, contains word to int mappings
  Outputs:
    id : int, id corresponding to word from wtoi_dict if word is present in wtoi_dict.
         If word is not present in wtoi_dict, id = <unk-0>
  """
  # YOUR CODE HERE
  id=wtoi_dict[word]
  return id

wtoi('holding', wtoi_dict)

def itow(id, itow_dict):
  """
  Inputs:
    id: int, integer id for which word is required
    itow_dict: dictionary, contains integer to word mappings
  Outputs:
    word: string, word corresponding to id from itow_dict, if id is present in itow_dict.
          If id is not present in itow_dict, word = <OOV>
  """
  word=itow_dict[id]
  return word

itow(8, itow_dict)

"""Numericalize your data in the **process_data** function, namely convert the sentences into a list of ids and the labels into label_ids. (Use the stoi function and  label_id in the cell below for mapping.). Your output for ['Two women are embracing while holding to go packages.',
 'The sisters are hugging goodbye while holding to go packages after just eating lunch.',
 'neutral'] may look like ([44, 39, 13, 192, 231, 102, 141, 246, 168],
  [43, 133, 13, 151, 135, 231, 102, 141, 246, 71, 185, 170, 159, 178],
  1) depending on your mappings
"""

label_id = {'entailment': 0, 'neutral': 1, 'contradiction': 2}

def process_data(data, label_id):
    """
    Input:
        data: list, a list of 3-sized tuples
        label_id: a dictionary of length 3 (as defined above)
        
    Output:
        numerialized_data: list, list of 3-sized tuples
        
    Action:
        1. Convert each sentence pair into a tuple of size 3, (token_id_list, token_id_list, int) and concatenate them altogether into a list.   
        2. Out-of-vocabulary tokens should be mapped to '<unk-0>'.
        
        i.e., 
        
        data = [sentence1, sentence2, gold_label] is given
        a. Now for each word in sentence1, find unique integer id corresponding to that word using wtoi(word)
        b. append all the integers obtained into a list (say n_s1)
        c. do same thing for sentence2 and store it in n_s2
        d. Now using label_id, store integer value corresponding to gold_label in n_y 
        e. append n_s1, n_s2 and n_y in a list 'numerialized_data'
        f. return numerialized_data
    """
    # YOUR CODE HERE
    numerialized_data=[]
    for i in data:
      stt1=[]
      stt2=[]
      st1=i[0].split()
      for j in st1:
        stt1.append(wtoi(j, wtoi_dict))
      st2=i[1].split()
      for k in st2:
        stt2.append(wtoi(k, wtoi_dict))
      lab_val=label_id[i[2]]
      numerialized_data.append((stt1,stt2,lab_val))
    return numerialized_data
    

        
numerialized_data = process_data(data, label_id)

print(numerialized_data)

