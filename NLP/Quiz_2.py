# -*- coding: utf-8 -*-
"""Shivangi Gupta - nlp_quiz2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nPFAKnV0DGljyrraWY29hA64cUmVlBQB

##  Softmax
Write softmax to convert vectors into probability distribution <br>
1) All the elements of probability distribution should be positive. <br>
2) Sum of all the elements of distribution will be 1. <br>

$Softmax(x_i) = 
\frac{\exp(x_i)}{\sum_j \exp(x_j)}$
"""

import math
import numpy as np
def softmax(vector):
  """
  Input : 
      vector: np array of floats
  Output:
      distribution: np array of floats of same size as that of input converted by using softmax
  """
  # YOUR CODE HERE
  s=0
  for i in vector:
    s=s+np.exp(i)
  distribution=np.exp(vector)/s
  return distribution

vector=np.array([0.23,0.65,0.87])
softmax(vector)

"""### Convert to One hot
Given a vector containing a probability distribution, convert it to one-hot vector with the max index having 1 and rest of the indices having 0
"""

def convert_to_one_hot(p):
  """
  Inputs:
    p: numpy array of 1 dimension, probability distribution
  Outputs:
    oh: one_hot vector corresponding to p
  """
  # YOUR CODE HERE
  oh=np.zeros((p.shape))
  temp=list(p)
  maxpos = temp.index(max(temp))
  oh[maxpos]=1
  oh=np.array(oh)
  return oh

p=np.array([0.1,0.7,0.2])
convert_to_one_hot(p)

"""## Complete analogy 

**Cosine Similarity:**
We can find the similarity in terms of  angle between two vectors. Formally, the Cosine Similarity  is  between two vectors  p  and  q  is defined as:

$s = \frac{p⋅q}{||p||||q||} $, where s∈[−1,1]<br>
Implement the function
"""

import math
import numpy as np
def cosine_similarity(v1,v2):
    """
    Input:
        v1: numpy array 
        v2: numpy array
        
    Output:
        v: single floating point value
        
        v = cosine similarity between v1 and v2 = (v1 dot v2)/{||v1||*||v2||}
    """
    # YOUR CODE HERE
    v1=np.array(v1)
    v2=np.array(v2)
    v = v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))
    return v



"""Consider the words $a, b, c, d$ and their corresponding word vectors $x_a, x_b, x_c, x_d$ such that they have this analogical relationship
$a:b :: c:d$ <br>
For eg.,<br>
Princess: Queen : : Prince : ? <br>
Complete the analogy by finding the missing word. <br>
To find out missing word "d", you need to find the word vector which has maximum cosine similarity with the vector $x_b - x_a + x_c$. The word corresponding to this vector is the word that will complete the analogy. In other words, you need to implment the following function <br>
$d = argmax_{x_i \in \mathcal{X}} \frac{(x_b-x_a+x_c)^Tx_i}{||x_b-x_a+x_c||\cdot ||x_i||}$
"""

def complete_analogy(a, b, c, word_dict):
  """
  Inputs:
    a, b, c: strings, with analogical relationship as described above
    word_dict: dictionary, dictionary with keys as words and values as corresponding word vectors
  Output:
      missing: str, the missing word d
  """
  # YOUR CODE HERE
  xa=np.array(word_dict.get(a))
  xb=np.array(word_dict.get(b))
  xc=np.array(word_dict.get(c))
  v=xb-xa+xc
  temp=[]
  tempkeys=list(word_dict.keys())
  tempkeys.remove(c)
  for v2 in word_dict.values():
      val= cosine_similarity(v,v2)  
      temp.append(val)
      
  maxpos = temp.index(max(temp))  
  out =tempkeys[maxpos] 
  return out

word_dict = {'princess':  [-1.720603, -3.560657],
             'queen': [-0.722603, -1.232549],
             'girl':  [-2.789075, -3.869762],
             'king':  [-0.370373, 0.576843],
            'prince': [-1.693504, 0.719822],
            'toy':  [2.78,  -0.71],
            'lady': [-1.693,  -0.7192],
            'student':  [-1.693504, 0.719822]}

complete_analogy('princess', 'queen','prince', word_dict)

word_dict = {'princess':	[-1.720603,	-3.560657],
             'queen':	[-0.722603,	-1.232549],
	           'girl':	[-2.789075,	-3.869762],
             'king':	[-0.370373,	0.576843],
            'prince':	[-1.693504,	0.719822],
            'toy':	[2.78,	-0.71],
            'lady':	[-1.693,	-0.7192],
            'student':	[-1.693504,	0.719822]}

'''test for complete_analogy'''
def test_complete_analogy():
    pass
test_complete_analogy()